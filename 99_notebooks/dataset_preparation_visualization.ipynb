{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fd48b8",
   "metadata": {},
   "source": [
    "# Dataset Preperation Visualization\n",
    "\n",
    "Use this code to ineractively view the different stages the data went through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4622afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config_path = \"../config.json\"\n",
    "config = json.load(open(config_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ba86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv(os.path.join(config[\"paths\"][\"datasets\"], \"test.csv\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d69237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random dataset_id\n",
    "dataset_id = random.choice(data[\"dataset_id\"].tolist())\n",
    "dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up paths from config and chosen dataset_id\n",
    "\n",
    "model_result_path = os.path.join(\n",
    "    config[\"paths\"][\"checkpoints\"],\n",
    "    config[\"face_geometry\"][\"model\"],\n",
    "    \"results\",\n",
    "    f\"epoch_{config['face_geometry']['epoch']:02d}_000000\",\n",
    ")\n",
    "bfm_path = config[\"paths\"][\"bfm\"]\n",
    "\n",
    "image_file = os.path.join(model_result_path, f\"{dataset_id}_M.png\")\n",
    "coefficient_path = os.path.join(model_result_path, f\"{dataset_id}_M.mat\")\n",
    "obj_path = os.path.join(model_result_path, f\"{dataset_id}_M.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename = image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9dc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = scipy.io.loadmat(coefficient_path)\n",
    "\n",
    "mesh = trimesh.load(obj_path)\n",
    "vertices_3d = mesh.vertices\n",
    "\n",
    "bfm_model_front = scipy.io.loadmat(os.path.join(bfm_path, 'BFM_model_front.mat'))\n",
    "\n",
    "landmark_indices = bfm_model_front['keypoints'].flatten() - 1\n",
    "landmark_vertices_3d = vertices_3d[landmark_indices.astype(int)]\n",
    "print(f\"3D landmarks shape: {landmark_vertices_3d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed64416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define facial landmark connections (typical 68-point connections)\n",
    "connections = [\n",
    "    # Jaw line (0-16)\n",
    "    list(range(0, 17)),\n",
    "    # Right eyebrow (17-21)\n",
    "    list(range(17, 22)),\n",
    "    # Left eyebrow (22-26)\n",
    "    list(range(22, 27)),\n",
    "    # Nose bridge (27-30)\n",
    "    list(range(27, 31)),\n",
    "    # Nose base (31-35)\n",
    "    list(range(31, 36)),\n",
    "    # Right eye (36-41)\n",
    "    list(range(36, 42)) + [36],\n",
    "    # Left eye (42-47)\n",
    "    list(range(42, 48)) + [42],\n",
    "    # Outer mouth (48-59)\n",
    "    list(range(48, 60)) + [48],\n",
    "    # Inner mouth (60-67)\n",
    "    list(range(60, 68)) + [60]\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(landmark_vertices_3d[:, 0], landmark_vertices_3d[:, 1], landmark_vertices_3d[:, 2], \n",
    "           c='red', s=20)\n",
    "\n",
    "for connection in connections:\n",
    "    ax.plot(landmark_vertices_3d[connection, 0], \n",
    "            landmark_vertices_3d[connection, 1], \n",
    "            landmark_vertices_3d[connection, 2], \n",
    "            'b-', linewidth=1)\n",
    "\n",
    "for i, (x, y, z) in enumerate(landmark_vertices_3d):\n",
    "    ax.text(x, y, z, str(i), fontsize=8, ha='center', va='center', \n",
    "            bbox=dict(boxstyle=\"round,pad=0.1\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('3D Facial Landmarks with Point Indices')\n",
    "ax.view_init(elev=90, azim=-90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a9a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoustic-to-anthropometric",
   "language": "python",
   "name": "acoustic-to-anthropometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
