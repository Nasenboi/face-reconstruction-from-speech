{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55242478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.config import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b50fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_paths = [\n",
    "os.path.join(CONFIG[\"paths\"][\"datasets\"], \"train_001_250037.feather\"),\n",
    "os.path.join(CONFIG[\"paths\"][\"datasets\"], \"train_002_250066.feather\"),\n",
    "os.path.join(CONFIG[\"paths\"][\"datasets\"], \"train_003_250037.feather\"),\n",
    "]\n",
    "\n",
    "val_path =       os.path.join(CONFIG[\"paths\"][\"datasets\"], \"/train_004_250125.feather\")\n",
    "test_path =      os.path.join(CONFIG[\"paths\"][\"datasets\"], \"/train_005_91744.feather\")\n",
    "new_test_path =  os.path.join(CONFIG[\"paths\"][\"datasets\"], \"/test_005.feather\")\n",
    "new_val_path =   os.path.join(CONFIG[\"paths\"][\"datasets\"], \"/val_004.feather\")\n",
    "new_train_path = os.path.join(CONFIG[\"paths\"][\"datasets\"], \"/train_001-003.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([\n",
    "    pd.read_feather(p)\n",
    "    for p in batch_paths\n",
    "])\n",
    "val_df = pd.read_feather(val_path)\n",
    "test_df = pd.read_feather(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.groupby('video_id').head(3)\n",
    "train_df = train_df.groupby('speaker_id').head(12)\n",
    "val_df = val_df.groupby('video_id').head(3)\n",
    "val_df = val_df.groupby('speaker_id').head(12)\n",
    "test_df = test_df.groupby('video_id').head(3)\n",
    "test_df = test_df.groupby('speaker_id').head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df.speaker_id.unique()), len(val_df.speaker_id.unique()), len(test_df.speaker_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aad0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_feather(new_train_path, compression=\"zstd\", compression_level=3)\n",
    "val_df.to_feather(new_val_path, compression=\"zstd\", compression_level=3)\n",
    "test_df.to_feather(new_test_path, compression=\"zstd\", compression_level=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoustic-to-anthropometric",
   "language": "python",
   "name": "acoustic-to-anthropometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
