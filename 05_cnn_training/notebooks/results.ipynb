{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e911a4b-504a-4b52-b97e-00a263124b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kapre\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Resizing, Conv2D\n",
    "from bfm import BFMGenerator\n",
    "import librosa\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Preset Variables if needed:\n",
    "RANDOM_STATE = 1\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "PROJECT_PATH = \"/app/project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc90a1f-41b9-4024-a9c8-5aac7f57a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE     = 16_000\n",
    "AUDIO_LENGTH_S  = 3\n",
    "SPEC_HOPSIZE    = 256\n",
    "SPEC_BLOCKSIZE  = 1024\n",
    "\n",
    "NUM_SAMPLES = SAMPLE_RATE * AUDIO_LENGTH_S\n",
    "TIME_STEPS = (NUM_SAMPLES - SPEC_BLOCKSIZE) // SPEC_HOPSIZE + 1\n",
    "N_MELS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddf3749-211a-42f8-bca3-ef7740da0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path: str):\n",
    "    y, sr = librosa.load(path, mono=True, sr=SAMPLE_RATE)\n",
    "    if len(y) > NUM_SAMPLES:\n",
    "        y = librosa.effects.trim(y)[0]\n",
    "    if len(y) > NUM_SAMPLES:\n",
    "        y = y[:NUM_SAMPLES]\n",
    "    elif len(y) < NUM_SAMPLES:\n",
    "        padding = NUM_SAMPLES - len(y)\n",
    "        pad_left = padding // 2\n",
    "        pad_right = padding - pad_left\n",
    "        y = np.pad(y, (pad_left, pad_right), mode='constant')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31f3e33-3911-4b98-96fa-3f2c0591352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = os.path.join(PROJECT_PATH, \"datasets\", \"test_005_ids.feather\")\n",
    "test_df = pd.read_feather(df_path)\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "ID_COLUMN_NAMES = [c for c in test_df.columns if \"id_\" in c]\n",
    "info_columns = [\n",
    "    \"speaker_id\",\n",
    "    \"face_id\",\n",
    "    \"gender\",\n",
    "    \"split\",\n",
    "    \"video_id\",\n",
    "    \"clip_id\",\n",
    "    \"batch\",\n",
    "    \"audio_path\"\n",
    "]\n",
    "\n",
    "test_df[\"dataset_id\"] = test_df.apply(\n",
    "    lambda row: f\"{row['speaker_id']}_{row['video_id']}_{row['clip_id']}\", \n",
    "    axis=1\n",
    ")\n",
    "test_df = test_df.set_index(\"dataset_id\")\n",
    "test_df[\"audio_path\"] = test_df.apply(\n",
    "    lambda row: os.path.join(PROJECT_PATH, \"audio\", f\"{row['speaker_id']}_{row['video_id']}_{row['clip_id']}.wav\"), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11159084-074f-4bd0-91c3-5b144cca8fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEST_FILES = 500\n",
    "\n",
    "X_test = np.array([load_audio(path) for path in test_df[\"audio_path\"].head(MAX_TEST_FILES)])\n",
    "X_test = X_test.reshape(-1, NUM_SAMPLES, 1)\n",
    "\n",
    "y_test = test_df[ID_COLUMN_NAMES].head(MAX_TEST_FILES).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213150d3-077f-4ead-992b-d6d4ff5e51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4ef08-d478-41d6-9429-b76b8a946924",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf.config.experimental.list_physical_devices(\"GPU\")) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a981c-cdf5-4190-9376-1590f11159ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(tf.config.experimental.list_physical_devices(\"GPU\")) > 0):\n",
    "    print(\"GPU is available!\")\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.75)\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e629ae96-6c39-41d4-a315-5bed31d73db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"stft_vgg16_fixed-29.11.09.37.14-1.1.keras\"\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(PROJECT_PATH, \"models\", MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36472a2-7695-4f3b-84fb-4273f3db2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c2f45-cf0c-43b7-a927-c8c632fb7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfmGenerator = BFMGenerator(bfm_folder = os.path.join(PROJECT_PATH, \"face_geometry\", \"bfm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d775a79-3922-4f1f-a3a1-feb71edf78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(y_test) - 1)\n",
    "\n",
    "y_test_tensor = torch.from_numpy(y_test[index]).float()\n",
    "test_predictions_tensor = torch.from_numpy(test_predictions[index]).float()\n",
    "bfmGenerator.plot_comparison(\n",
    "    id_coeffs_list=[\n",
    "        y_test_tensor, test_predictions_tensor\n",
    "    ],\n",
    "    titles=[\n",
    "        \"Target Face\", \"Predicted Face\"\n",
    "    ],\n",
    "    plot_type=\"plotly\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45326513-10ae-4d1c-88ff-f0842f06250d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-training",
   "language": "python",
   "name": "cnn-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
